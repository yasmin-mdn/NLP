{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34kSvaXZejxP"
      },
      "source": [
        "# **HW2 - Text Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAnj55oxdpiQ"
      },
      "source": [
        "## 1. IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "JFlKzNjcKeQr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ElC24F9DdRxq"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n",
        "INDEX_FROM=3\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(index_from=INDEX_FROM)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words=stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKT3NiipRbnd",
        "outputId": "1bbbc804-0b0b-4c53-c0c1-3b57dac372c1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpXc193Vd30r"
      },
      "source": [
        "## 2. Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tXfDtZQhINU"
      },
      "source": [
        "### 2.1. Any data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "train_sents=[]\n",
        "test_sents=[]\n",
        "word_to_id = imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "word_to_id[\"<UNUSED>\"] = 3\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}\n",
        "for j in range(0,len(x_train)):\n",
        "  decoded =  [ id_to_word[id] for id in x_train[j] if id_to_word[id] != \"br\" and  not id_to_word[id] in stop_words and not (id_to_word[id].isdigit()) and not id_to_word[id] in string.punctuation] \n",
        "  train_sents.append(decoded)\n",
        "\n",
        "for j in range(0,len(x_test)):\n",
        "  decoded = [id_to_word[id] for id in x_test[j] if id_to_word[id] != \"br\" and  not id_to_word[id] in stop_words  and not (id_to_word[id].isdigit()) and not id_to_word[id] in string.punctuation ] \n",
        "  test_sents.append(decoded)"
      ],
      "metadata": {
        "id": "DCMH-BGOSy32"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3YfvFW8g1ee"
      },
      "source": [
        "### 2.2. Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-31y4Flg6Z4"
      },
      "source": [
        "### 2.3. Stemming"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "snow_stemmer = SnowballStemmer(language='english')\n",
        "train_sttemed_sents=[]\n",
        "test_sttemed_sents=[]\n",
        "for sent in train_sents:\n",
        "    tmp = [snow_stemmer.stem(w) for w in sent]\n",
        "    train_sttemed_sents.append(tmp)\n",
        "\n",
        "for sent in test_sents:\n",
        "    tmp = [snow_stemmer.stem(w) for w in sent]\n",
        "    test_sttemed_sents.append(tmp)"
      ],
      "metadata": {
        "id": "Bh4n94rOcd4t"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imQqe33JeZqS"
      },
      "source": [
        "## 3. Build Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opNqhDhai4oJ"
      },
      "source": [
        "### 3.1. Uni-Gram"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_neg = 0\n",
        "count_pos = 0\n",
        "for i, tmp in enumerate(train_sttemed_sents):\n",
        "      if y_train[i]==0:\n",
        "             count_pos += len(tmp)\n",
        "      elif y_train[i]==1 :\n",
        "             count_neg += len(tmp)\n",
        "unigram = {'neg':{}, 'pos':{}}\n",
        "unigram_prop = {'neg':{}, 'pos':{}}\n",
        "\n",
        "for i, sample in enumerate(train_sttemed_sents):\n",
        "    if y_train[i] == 0:\n",
        "        key = 'neg'\n",
        "        n_key = 'pos'\n",
        "    elif y_train[i] == 1 :\n",
        "        key = 'pos'\n",
        "        n_key = 'neg'\n",
        "\n",
        "    fdist_item = nltk.FreqDist(sample).items()\n",
        "    for k, v in fdist_item :\n",
        "        if k in unigram[key].keys():\n",
        "            unigram[key][k] += v\n",
        "        else:\n",
        "            unigram[key][k] = v\n",
        "\n",
        "        if not k in unigram[n_key].keys():\n",
        "            unigram[n_key][k] = 0\n",
        "\n",
        "unigram_prop['neg'] = {k : (v + 1) / (count_neg + len(unigram['neg']) + 1) for k, v in unigram['neg'].items()}\n",
        "unigram_prop['neg'][-1] = 1 / (count_neg + len(unigram['neg']) + 1)\n",
        "unigram_prop['pos'] = {k : (v + 1) / (count_pos + len(unigram['pos']) + 1) for k, v in unigram['pos'].items()}\n",
        "unigram_prop['pos'][-1] = 1 / (count_pos + len(unigram['pos']) + 1)"
      ],
      "metadata": {
        "id": "M_5xGRP1MLJ4"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I1UwalSjA63"
      },
      "source": [
        "### 3.2. Bi-Gram\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "J4nmoJX7jG8-"
      },
      "outputs": [],
      "source": [
        "# # NLTK function to generate ngrams\n",
        "# import nltk\n",
        "# from nltk.util import ngrams\n",
        "# bi_GRAMS=[]\n",
        "# for sent in train_sttemed_sents:\n",
        "#   temp=ngrams(sequence= sent, n=2)\n",
        "#   bi_GRAMS.append(temp)\n",
        "\n",
        "# # for t in bi_GRAMS:\n",
        "# #   for grams in t:\n",
        "# #     print(grams)\n",
        "\n",
        "bigram = {'neg':{}, 'pos':{}}\n",
        "bigram_prop = {'neg':{}, 'pos':{}}\n",
        "for i, sample in enumerate(train_sttemed_sents):\n",
        "    if y_train[i] == 0:\n",
        "        key = 'neg'\n",
        "        n_key = 'pos'\n",
        "    elif y_train[i] == 1 :\n",
        "        key = 'pos'\n",
        "        n_key = 'neg'\n",
        "    bgs = nltk.bigrams(sample)\n",
        "    fdist_items = nltk.FreqDist(bgs).items()\n",
        "    for k, v in fdist_items:\n",
        "        if k in bigram[key].keys():\n",
        "            bigram[key][k] += v\n",
        "        else:\n",
        "            bigram[key][k] = v\n",
        "        if not k in bigram[n_key].keys():\n",
        "            bigram[n_key][k] = 0\n",
        "\n",
        "bigram_prop['pos'] = {k : (v + 1) / (unigram['pos'][k[0]] + len(bigram['pos']) + 1) for k, v in bigram['pos'].items()}\n",
        "bigram_prop['pos'][-1] = 1 / (unigram['pos'][k[0]] + len(bigram['pos']) + 1)\n",
        "bigram_prop['neg'] = {k : (v + 1) / (unigram['neg'][k[0]] + len(bigram['neg']) + 1) for k, v in bigram['neg'].items()}\n",
        "bigram_prop['neg'][-1] = 1 / (unigram['neg'][k[0]] + len(bigram['neg']) + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCICu7qpjI9z"
      },
      "source": [
        "### 3.3. Tri-Gram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "t70q9YLTjIWD"
      },
      "outputs": [],
      "source": [
        "# # NLTK function to generate ngrams\n",
        "# import nltk\n",
        "# from nltk.util import ngrams\n",
        "# tri_GRAMS=[]\n",
        "# for sent in train_sttemed_sents:\n",
        "#   temp=ngrams(sequence= sent, n=3)\n",
        "#   tri_GRAMS.append(temp)\n",
        "trigram = {'neg':{}, 'pos':{}}\n",
        "trigram_prop = {'neg':{}, 'pos':{}}\n",
        "for i, sample in enumerate(train_sttemed_sents):\n",
        "    if y_train[i] == 0:\n",
        "        key = 'neg'\n",
        "        n_key = 'pos'\n",
        "    elif y_train[i] == 1 :\n",
        "        key = 'pos'\n",
        "        n_key = 'neg'\n",
        "    bgs = nltk.trigrams(sample)\n",
        "    fdist_items = nltk.FreqDist(bgs).items()\n",
        "    for k, v in fdist_items:\n",
        "        if k in trigram[key].keys():\n",
        "            trigram[key][k] += v\n",
        "        else:\n",
        "            trigram[key][k] = v\n",
        "        if not k in trigram[n_key].keys():\n",
        "            trigram[n_key][k] = 0\n",
        "trigram_prop['pos'] = {k : (v + 1) / (bigram['pos'][(k[0], k[1])] + len(trigram['pos']) + 1) for k, v in trigram['pos'].items()}\n",
        "trigram_prop['pos'][-1] = 1 / (bigram['pos'][(k[0], k[1])] + len(trigram['pos']) + 1)\n",
        "trigram_prop['neg'] = {k : (v + 1) / (bigram['neg'][(k[0], k[1])] + len(trigram['neg']) + 1) for k, v in trigram['neg'].items()}\n",
        "trigram_prop['neg'][-1] = 1 / (bigram['neg'][(k[0], k[1])] + len(trigram['neg']) + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.  Naive Beyes"
      ],
      "metadata": {
        "id": "Ghi4wytqcR9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import bigrams,trigrams,FreqDist\n",
        "def NB(ngram_type,probs,arr):\n",
        "    neg_pred = len(y_train[y_train==0]) / len(y_train)\n",
        "    pos_pred = len(y_train[y_train==1]) / len(y_train)\n",
        "\n",
        "    if ngram_type == 1:\n",
        "        ngram = arr\n",
        "    elif ngram_type == 2:\n",
        "        ngram = bigrams(arr)\n",
        "    elif  ngram_type == 3 :\n",
        "        ngram = trigrams(arr)\n",
        "    else:\n",
        "      return\n",
        "    fdist = FreqDist(ngram)\n",
        "\n",
        "    for k, v in fdist.items():\n",
        "        if k in probs['neg']:\n",
        "            neg_pred *= probs['neg'][k]\n",
        "        else:\n",
        "            neg_pred *= probs['neg'][-1]\n",
        "        if k in probs['pos']:\n",
        "            pos_pred *= probs['pos'][k]\n",
        "        else:\n",
        "            pos_pred *= probs['pos'][-1]\n",
        "        if pos_pred < 10**(-10) or neg_pred < 10**(-10):\n",
        "            pos_pred *= 10**(10)\n",
        "            neg_pred *= 10**(10)\n",
        "        elif pos_pred > 10**10 or neg_pred > 10**10:\n",
        "            pos_pred *= 10**(-10)\n",
        "            neg_pred *= 10**(-10)\n",
        "       \n",
        "\n",
        "    return neg_pred, pos_pred\n",
        "\n"
      ],
      "metadata": {
        "id": "1WoNIPbISHpV"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJj1mXJJd7eR"
      },
      "source": [
        "## 5. Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unigram\n",
        "preds_uni = []\n",
        "for sample in test_sttemed_sents:\n",
        "        neg_pred, pos_pred = NB(1, unigram_prop, sample)\n",
        "        if neg_pred > pos_pred:\n",
        "            preds_uni.append(0)\n",
        "        else:\n",
        "            preds_uni.append(1)\n",
        "y_pred_unigram=np.array(preds_uni)\n",
        "\n",
        "#bigram\n",
        "preds_bi = []\n",
        "for sample in test_sttemed_sents:\n",
        "        neg_pred, pos_pred = NB(2, bigram_prop, sample)\n",
        "        if neg_pred > pos_pred:\n",
        "            preds_bi.append(0)\n",
        "        else:\n",
        "            preds_bi.append(1)\n",
        "y_pred_bigram=np.array(preds_bi)\n",
        "#trigram\n",
        "preds_tri = []\n",
        "for sample in test_sttemed_sents:\n",
        "        neg_pred, pos_pred = NB(3, trigram_prop, sample)\n",
        "        if neg_pred > pos_pred:\n",
        "            preds_tri.append(0)\n",
        "        else:\n",
        "            preds_tri.append(1)\n",
        "y_pred_trigram=np.array(preds_tri)"
      ],
      "metadata": {
        "id": "ZYqKaxQbxflQ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Precision For unigram:', \"{:.3f}\".format(precision_score(y_test, y_pred_unigram)))\n",
        "print('Precision For bigram:', \"{:.3f}\".format(precision_score(y_test, y_pred_bigram)))\n",
        "print('Precision For trigram', \"{:.3f}\".format(precision_score(y_test, y_pred_trigram)))\n",
        "print(\"//////////////////////////////\")\n",
        "print('Recall For unigram:', \"{:.3f}\".format(recall_score(y_test, y_pred_unigram)))\n",
        "print('Recall For bigram:',\"{:.3f}\".format(recall_score(y_test, y_pred_bigram)))\n",
        "print('Recall For trigram', \"{:.3f}\".format(recall_score(y_test, y_pred_trigram)))\n",
        "print(\"//////////////////////////////\")\n",
        "print('F1 Score For unigram:', \"{:.3f}\".format(f1_score(y_test, y_pred_unigram)))\n",
        "print('F1 Score For bigram:',\"{:.3f}\".format(f1_score(y_test, y_pred_bigram)))\n",
        "print('F1 Score For trigram', \"{:.3f}\".format(f1_score(y_test, y_pred_trigram)))\n",
        "print(\"//////////////////////////////\")\n",
        "print('Accuracy For unigram:', \"{:.3f}\".format(accuracy_score(y_test, y_pred_unigram)))\n",
        "print('Accuracy For bigram:',\"{:.3f}\".format(accuracy_score(y_test, y_pred_bigram)))\n",
        "print('Accuracy For trigram', \"{:.3f}\".format(accuracy_score(y_test, y_pred_trigram)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us84p9suM4pu",
        "outputId": "c821c222-be33-49e5-9f36-812a893a5943"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision For unigram: 0.753\n",
            "Precision For bigram: 0.873\n",
            "Precision For trigram 0.792\n",
            "//////////////////////////////\n",
            "Recall For unigram: 0.922\n",
            "Recall For bigram: 0.831\n",
            "Recall For trigram 0.721\n",
            "//////////////////////////////\n",
            "F1 Score For unigram: 0.829\n",
            "F1 Score For bigram: 0.852\n",
            "F1 Score For trigram 0.755\n",
            "//////////////////////////////\n",
            "Accuracy For unigram: 0.810\n",
            "Accuracy For bigram: 0.855\n",
            "Accuracy For trigram 0.766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sample in enumerate(test_sttemed_sents):\n",
        "    neg_pred, pos_pred = NB(1, unigram_prop, test_sttemed_sents[idx])\n",
        "    if (y_test[idx] == 1)!= (neg_pred < pos_pred):\n",
        "      print(idx)\n",
        "      print(test_sttemed_sents[idx])\n",
        "      print('y_test:', y_test[idx] == 1)\n",
        "      neg_pred, pos_pred = NB(1, unigram_prop, test_sttemed_sents[idx])\n",
        "      print('unigram:', \"{:.20f}\".format(neg_pred), \"{:.20f}\".format(pos_pred), neg_pred < pos_pred)\n",
        "      neg_pred, pos_pred = NB(2, bigram_prop, test_sttemed_sents[idx])\n",
        "      print('bigram:', \"{:.20f}\".format(neg_pred), \"{:.20f}\".format(pos_pred), neg_pred < pos_pred)\n",
        "      neg_pred, pos_pred = NB(3, trigram_prop, test_sttemed_sents[idx])\n",
        "      print('trigram:', \"{:.20f}\".format(neg_pred), \"{:.20f}\".format(pos_pred), neg_pred < pos_pred)\n",
        "      print('####################')\n",
        "      break\n",
        "\n",
        "for idx, sample in enumerate(test_sttemed_sents):\n",
        "    neg_pred, pos_pred = NB(2, bigram_prop,test_sttemed_sents[idx])\n",
        "    if bool(y_test[idx] == 1)!= bool(neg_pred < pos_pred) :\n",
        "      print(idx)\n",
        "      print(test_sttemed_sents[idx])\n",
        "      print('y_test:', y_test[idx] == 1)\n",
        "      neg_pred, pos_pred = NB(1, unigram_prop, test_sttemed_sents[idx])\n",
        "      print('unigram:', \"{:.20f}\".format(neg_pred), \"{:.20f}\".format(pos_pred), neg_pred < pos_pred)\n",
        "      neg_pred, pos_pred = NB(2, bigram_prop,test_sttemed_sents[idx])\n",
        "      print('bigram:', \"{:.20f}\".format(neg_pred), \"{:.20f}\".format(pos_pred), neg_pred < pos_pred)\n",
        "      neg_pred, pos_pred = NB(3, trigram_prop, test_sttemed_sents[idx])\n",
        "      print('trigram:', \"{:.20f}\".format(neg_pred), \"{:.20f}\".format(pos_pred), neg_pred < pos_pred)\n",
        "      print('####################')\n",
        "      break\n",
        "\n",
        "for idx, sample in enumerate(test_sttemed_sents):\n",
        "    neg_pred, pos_pred = NB(3, trigram_prop,test_sttemed_sents[idx])\n",
        "    neg_pred1, pos_pred1 = NB(1,unigram_prop,test_sttemed_sents[idx])\n",
        "    if bool(neg_pred1 < pos_pred1) == bool(y_test[idx] == 1) and bool(neg_pred < pos_pred) != bool(y_test[idx] == 1)  :\n",
        "      print(idx)\n",
        "      print(test_sttemed_sents[idx])\n",
        "      print('y_test:', y_test[idx] == 1)\n",
        "      neg_pred, pos_pred = NB(1, unigram_prop, test_sttemed_sents[idx])\n",
        "      print('unigram:', \"{:.20f}\".format(neg_pred), \"{:.20f}\".format(pos_pred), neg_pred < pos_pred)\n",
        "      neg_pred, pos_pred = NB(2, bigram_prop,test_sttemed_sents[idx])\n",
        "      print('bigram:', \"{:.20f}\".format(neg_pred), \"{:.20f}\".format(pos_pred), neg_pred < pos_pred)\n",
        "      neg_pred, pos_pred = NB(3, trigram_prop,test_sttemed_sents[idx])\n",
        "      print('trigram:', \"{:.20f}\".format(neg_pred), \"{:.20f}\".format(pos_pred), neg_pred < pos_pred)\n",
        "      print('####################')\n",
        "      break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL8myBg0M--h",
        "outputId": "53fb0150-42c3-4054-c359-dfbb2f52a246"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "['<start>', 'emperor', 'richard', 'haydn', 'dog', 'betroth', 'johanna', 'joan', 'fontain', 'dog', 'howev', 'virgil', 'bing', 'crosbi', 'arriv', 'town', 'sell', 'record', 'player', 'emperor', 'dog', 'attack', 'johanna', 'dog', 'reveng', 'attack', 'virgil', 'banish', 'town', 'psychoanalyst', 'insist', 'johanna', 'dog', 'must', 'confront', 'dog', 'overcom', 'doggi', 'fear', 'arrang', 'dog', 'fall', 'love', 'virgil', 'johanna', 'rest', 'film', 'pass', 'romanc', 'end', 'johanna', 'dog', 'give', 'birth', 'father', 'dog', 'stori', 'weak', 'vehicl', 'use', 'tri', 'creat', 'stori', 'human', 'terribl', 'storylin', 'main', 'music', 'piec', 'rubbish', 'bad', 'song', 'dread', 'choreographi', 'extrem', 'bore', 'film', 'bing', 'mani', 'word', 'sentenc', 'deliv', 'almost', 'irrit', 'manner', 'funni', 'ever', 'meant', 'bing', 'joan', 'done', 'much', 'better']\n",
            "y_test: False\n",
            "unigram: 0.00000000018930282923 0.00000002048303390717 True\n",
            "bigram: 2365.02400839971369350678 0.00109233333028247847 False\n",
            "trigram: 0.00000694624858749255 0.00000080109583952223 False\n",
            "####################\n",
            "5\n",
            "['<start>', \"i'm\", 'absolut', 'disgust', 'movi', 'sold', 'love', 'movi', 'email', 'disney', 'increas', 'demand', \"they'd\", 'eventu', 'sell', \"i'd\", 'buy', 'copi', 'everybodi', 'know', 'everyth', 'everybodi', 'movi', 'good', 'job', 'figur', 'disney', 'put', 'movi', 'dvd', 'vhs', 'rental', 'store', 'least', 'seen', 'copi', 'wick', 'good', 'movi', 'seen', 'kid', 'new', 'generat', 'get', 'see', 'think', 'least', 'put', 'back', 'channel', 'movi', 'deserv', 'cheap', 'download', 'deserv', 'real', 'thing', \"i'm\", 'movi', 'dvd']\n",
            "y_test: True\n",
            "unigram: 0.00000002817773238359 0.00000007098813014424 True\n",
            "bigram: 0.00000002402370655712 0.00000000694083682389 False\n",
            "trigram: 0.00372744263789332201 0.00441620987511858864 True\n",
            "####################\n",
            "1\n",
            "['<start>', 'film', 'requir', 'lot', 'patienc', 'focus', 'mood', 'charact', 'develop', 'plot', 'simpl', 'mani', 'scene', 'take', 'place', 'set', 'franc', 'austen', 'sandi', 'denni', 'charact', 'apart', 'film', 'build', 'disturb', 'climax', 'charact', 'creat', 'atmospher', 'rife', 'sexual', 'tension', 'psycholog', 'trickeri', 'interest', 'robert', 'altman', 'direct', 'consid', 'style', 'structur', 'film', 'still', 'trademark', 'altman', 'audio', 'style', 'evid', 'think', 'realli', 'make', 'film', 'work', 'brilliant', 'perform', 'sandi', 'denni', 'definit', 'one', 'darker', 'charact', 'play', 'perfect', 'convinc', 'scari', 'michael', 'burn', 'good', 'job', 'mute', 'young', 'man', 'regular', 'altman', 'player', 'michael', 'murphi', 'small', 'part', 'solemn', 'moodi', 'set', 'fit', 'content', 'stori', 'well', 'short', 'movi', 'power', 'studi', 'loneli', 'sexual', 'repress', 'desper', 'patient', 'soak', 'atmospher', 'pay', 'attent', 'wonder', 'written', 'script', 'prais', 'robert', 'altman', 'one', 'mani', 'film', 'deal', 'unconvent', 'fascin', 'subject', 'matter', 'film', 'disturb', 'sincer', 'sure', 'elicit', 'strong', 'emot', 'respons', 'viewer', 'want', 'see', 'unusu', 'film', 'might', 'even', 'say', 'bizarr', 'worth', 'time', 'unfortun', 'difficult', 'find', 'video', 'store', 'may', 'buy', 'internet']\n",
            "y_test: True\n",
            "unigram: 0.00000000037924195660 555.02757185687346463965 True\n",
            "bigram: 0.00000009151660757814 10.61729423325716936688 True\n",
            "trigram: 0.01090983298296508558 0.00017707702542392575 False\n",
            "####################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSFPHFHmlmF1"
      },
      "source": [
        "## Good Luck!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "NLP_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}